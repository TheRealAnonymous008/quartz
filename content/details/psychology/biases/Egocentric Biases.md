* This is the tendency to rely too heavily on one's own perspective, or have a different perception of oneself relative to others.
* *The root of many egocentric biases is overestimation of the Self and underestimation of Others and the Environment. *
	* This also includes overestimating how "rational" we are compared to others, and underestimating how "emotional" we are.

* **Barnum Effect** - individuals believe that generic information (i.e., horoscopes or supposed personalized products), which could apply to anyone, applies specifically to themselves.
	* It arises from the common tendency to attach personal meaning to general statements, called **subjective validation**.
	* It can also be attributed to the Pollyanna effect.

* **Bias Blind Spot** - the biased belief that biases impact others more than oneself. 
	* It can be attributed to people viewing themselves in a positive light, and how being biased is viewed in a negative manner.
	* Additionally, *people like to believe they are aware of how and why they make their decisions.*

* **Dunning-Kruger Effect** - a person's lack of knowledge and skills in a certain areas cause them to overestimate their own competence. 
	* Conversely, those who excel in a given task think the task is simple for everyone and underestimate their relative abilities.
	* *People who don't know much about a subject don't have knowledge or skills to spot their own mistakes* so they don't see their incompetence and assume they do great.
	* *People who know a lot don't have the ability to notice their specialty*, because their work comes so naturally to them that they don’t realize it’s not this way for everyone

* **Empathy Gap Effect** - people tend to underestimate the influence of varying mental states on their behavior and make decisions that only satisfy current feelings.
	* One's response in a cold state (calm mental state) differs from that in a hot state (stressed) due to powerful emotions.
	* It is suggested that we rely heavily on our current mental state to predict future behaviors.
	* When we are in a cold state, we like to believe that we will also act rationally in the future, even though we may transition to a hot state.
	* When we are in a hot state, we do not understand that our decisions are influenced on our immediate emotions as well.

* **False Consensus Effect** - people tend to see their own personal qualities, beliefs and actions are widespread through the general population.
	* It can be derived *from a desire to conform* along with the belief that the collective opinion of the group generalizes to the larger population.
	* When faced with uncertainty and a limited sample from which to make decisions, people often "project" themselves onto the situation and thus make generalizations with an egocentric view.
	* *This tends to be applied to negative traits*. Thus, it can be argued as a form of rationalization

* **False Uniqueness Bias** - people often think they are more unique than others in regards to desirable traits.  *This tends to be applied to positive traits*. 
	* One possible explanation is related to egocentrism, the anchoring effect, and the availability heuristic.

* **Hard-Easy Effect** - occurs when we incorrectly predict our ability to complete tasks depending on their level of difficulty.
	* *We are overconfident in how successful will be at hard tasks and underconfident at how successful we will be at easy ones
	* We approach uncertainty irrationality since we are not good predictors of our abilities.
	* Similar to the Dunning-Kruger effect, we can attribute this to a lack of knowledge about our own deficiencies.
	* The overconfidence may also be attributed to confirmation bias. We focus on why our answers are right rather than how they could be wrong.
	* **Bikeshedding** can also explain our underconfidence for easy tasks. The longer we spend thinking of an answer to an easy question, the more likely we conjure up evidence that our answer is wrong.

* **Illusion of Asymmetric Insight** - people tend to view their own spontaneous responses to others' questions as unrevealing even though they view others' similar responses as meaningful.

* **Illusion of Control** - the tendency to overestimate one's control or influence over events. 
	* It arises in situations which are clearly random, but we try to rationalize that we did have some influence over it.
	* At its core, it stems from *our desire to be in control* coupled with the Pollyanna effect, and misattributed causality.
	* When we’re in an unpleasant situation, just knowing that we could stop it makes it much easier for us to tolerate it.
	* It is the opposite of learned helplessness.
	* We tend to come to conclusions about why things happen without reasoning through it.

* **Illusion of Explanatory Depth** - the belief that we understand more about the world than we actually do.
	* Having to explain knowledge brings about the realization that one knows much less than initially thought.
	* The following are some reasons why this happens:
		* **Change Blindness** - when information is not directly in front of us, our memories and conceptions of it are shaky at best, but we are none the wiser.
		* **Illusion of Levels** - being able to describe different levels of an item or concept inflates our perception of how much we know about it.
		* *Explanations are not discrete and continue on until the audience understands*. Anything that one can explain leads to the belief of understanding even if the explanation is not at all comprehensive.
		* *We rarely explain things to begin with*.

* **Illusion of Transparency** - the tendency to overestimate the degree to which one's personal mental state is known to others and vice versa. 

* **Illusion of Validity** - the tendency to be overconfident in the accuracy of our judgments and predictions regarding a given data set, especially when the data tells a story.
	* One reason for this is the *representativeness heuristic*, wherein we view things in relation to a prototypical example. People tend to select outcomes based on how they represent the essential features of the evidence.
	* Another reason is the *[[False Priors|Base Rate Fallacy]]*, the tendency to ignore prior probabilities. Individuating information makes us confident in our predictions, but we are prone to ignoring the priors.
	* Another reason is [[Confirmation Bias|Confirmation Bias]] since we are prone to cherry picking.

* **Illusory Superiority** - a person overestimates their own qualities and abilities in relation to the same qualities and abilities of other people.
	* This appears to be dependent on culture 
	* One reason why this happens is due to the *better than average heuristic* - that people exaggerate their characteristics towards the perceived ideal.
	* Another reason is cherry picking--choosing their own strengths and others' weaknesses.
	* Another reason is focalism--more focus is put on the self.

* **Naive Cynicism** - the tendency to assume that other people are more egocentrically biased than is the case.
	* It hinges on the premise (1) "I am not biased", (2) "You are biased if you disagree with me", (3) "Your intentions / actions reflect your underlying egocentric biases"

* **Naive Realism** - the tendency to believe that we are objective, and those who disagree with us are uninformed, irrational or biased. This leads to dismissing views other than our own as "irrational"
	* It hinges on the premise (1) "I am not biased", (2) "Reasonable people are not biased", (3) "All others are biased".
	* This is related to the *false consensus effect* where we assume our opinions are held by others.
	* We think that things exist independently of us which is why their ‘real’ state can be perceived.

* **Overconfidence Effect** - people tend to be prone to overconfidence. They are more confident in their own judgments more than the objective accuracy of those judgments.
	* One type manifests as the tendency to **overestimate** one's ability, knowledge, standing or performance. This is especially apparent in the context of hard tasks or tasks where one is not skilled.
	* Another type  is as **overprecision**, that is excessive confidence that one knows the truth.
	* Another type is **overplacement** where one erroneously rates someone as better than others (i.e., better than average.)
		* Curiously, the better-than-average effect applies for easy tasks. For hard tasks, it becomes worse-than-average.

* **Planning Fallacy** - people tend to underestimate how much time, costs, or risks they need to complete a task, at the same time overestimating the benefits of these actions.
	* The **segmentation effect** is defined as the time allocated for a task being significantly smaller than the sum of the time allocated to individual smaller sub-tasks.
	* One reason why this happens is *we are biased towards optimism*, we also tend to *write off negative information*.
	* Another reason is that we become anchored to our original plans, we continue thinking in terms of initial conditions even when these conditions were too optimistic or no longer apply.

* **Pollyanna Effect**  - positive statements about oneself tend to be more remembered than negative ones. *Individuals are biased to accept praise and reject criticisms easily*.

* **Restraint Bias** - the tendency for people to overestimate their ability control impulsive behavior, leading to greater exposure to temptation and increased impulsiveness.

* **Trait Ascription Bias** - the tendency for people to view themselves as relatively variable in terms of personality, while viewing others as more predictable.
	* This can be seen as an example of the [[Availability Heuristic|availability heuristic]] where information about the self is more accessible than others.

* **Third Person Effect** - predicts that people tend to perceive that mass media messages have a greater effect on others than on themselves based on personal biases.