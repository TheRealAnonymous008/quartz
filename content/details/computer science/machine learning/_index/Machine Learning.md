* It is interesting how most of the advances in Machine Learning try to copy the advances in [[Biology]] NNs simulate real biological networks; RNNs via LSTMs try to simulate our ability to remember; and Attention Mechanisms simulate our ability to focus on certain things. Even the manner of learning mimics real life.  This  leads to the conjecture that *The next advancements in AI as a whole will likely necessitate understanding and simulating our cognitive and human aspects*

* As of writing (2023), this field has been rapidly growing. While there are ways for it to be used poorly, it can also finally bring about a better society overall--a change in values and way of thinking; more convenience, and more time for people to pursue their passions for their own sake, while letting machines do the rest. 

* The methods of Neural Style Transfer probably indicate that neural networks can extract the "essence" of an image in the same manner humans recognize an object even if it is rendered or perceived differently.

* Automated Theorem Proving and [[Machine Learning and Mathematical Reasoning|Mathematical Reasoning]] is very interesting. Maybe we'll have an ML model that will be as good as a mathematician.

* [Silicon-based Photonics is a promising future for running large AI models in a more efficient way]((https://www.youtube.com/watch?v=t0yj4hBDUsc)

* [As of June 2023, the development of LLMs has felt stifled due to alignment concerns. In my opinion that shouldn't be the case considering we are limiting the potential advancement of ML towards AGI](https://www.youtube.com/watch?v=WbruLepPZyU)


# Topics
* [[Low Level of Training a Model]]
* [[Multimodal Models]]
* [[Supervised Learning]]
* [[Unsupervised Learning]]
* [[Reinforcement Learning]]
* [[AI in Education]]
* [[Machine Learning and Mathematical Reasoning]]
# Tools
* [HuggingFace](https://huggingface.co)- an open source platform provider of machine learning technologies. They also provide datasets.
* [PyTorch](https://pytorch.org) - a machine learning framework. *Opinon:* More developer friendly than TensorFlow
* [sentencepiece](https://github.com/google/sentencepiece)- a tokenizer that supports byte pair encoding. It allows ofr a purely end-to-end system that does not depend on language-specific pre/post-processing
* [tiktoken](https://github.com/openai/tiktoken)- a fast byte pair encoding tokenzier
# Links
* [[$Dive into Deep Learning by Zhang, Lipton, Li and Smola]] - An excellent introductory book about deep learning. 

* [Running Neural Networks on Meshes of Light](https://www.youtube.com/watch?v=t0yj4hBDUsc)

* [AAAI](https://aaai.org) - contains a collection of conference papers about AI and ML 
* [ICML proceedings](https://icml.cc)  - also has Tutorials.
* [ICLR proceedings](https://iclr.cc)  
* [IJCAI proceedings](https://www.ijcai.org) 
* [NeuroIPS](https://nips.cc) - another trusted conference for AI/ML matters.
* [Notes on AI](https://notesonai.com/Notes+on+AI)  - a published obsidian vault containing notes on ML
* [paperswithcode](https://paperswithcode.com) - A site that archives different ML research papers.