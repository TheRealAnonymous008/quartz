* Pathologies in a [[System Dynamics|system]] arise due to how [[Characterizing Systems#Systems as Models|surprising]] systems tend to be.

![[System Archetypes.png]]
<figcaption> A collection of common system archetypes Attribution: Mywikipedian, CC BY-SA 4.0  </figcaption>

* **Policy Resistance**  - *when various actors try to pull a system stock towards various goals*. Any new policy, especially if it is effective  just pulls the stock farther from the goals of other actors, and produces additional resistance, with a result that no one likes, but that everyone expends considerable effort in maintaining. 
	* It comes from the bounded rationalities of the actors in the system. In particular, they arise when the goals of subsystems are different to the goals of the global system. 
	* The greater the *discrepancy between personal and societal goals*, the more resistant to change since agent actions counter each other.
	* Remedies: 
		* *Introduce overpowering changes that can temporarily destabilize the system*.
		*  *Give up ineffective policies altogether and allow the system to simply evolve*. Often, the system won't evolve in a bad direction and you can use your resources to realize goals in a mutually satisfactory way. 
		* *Align the goals of the subsystems with the goals of the whole system*. 

* **The Tragedy of the Commons** - When there is a commonly shared resource or sink, *every user benefits directly from its use but shares the costs of its abuse with everyone else*. 
	* Therefore, there is very weak feedback from the condition of the resource to the decisions of the resource users. The consequence is overuse of the resource until it become unavailable to anyone. 
	* It arises from *missing or extremely delayed feedback* from the resource to the growth of the users of that resource. Bounded rationality then dictates that users shouldn't limit themselves. 
	* Remedies: 
		* *Educate and exhort*. Appeal to [[morality]]. Help people see the consequences of unrestrained use of the commons. 
			* It keeps use of the commons low enough that the resource is no longer threatened
			* Less reliable since individuals can simply not align themselves with these morals. 
		* *Privatize the commons*. Divide it up so each person reaps the consequences of their actions.  Privatization means that the only person a user can harm from their overuse is themselves. 
			* It makes a direct feedback link from the condition of the resource to those who use it. 
			* Infeasible for some resources which cannot be privatized. 
		* *Regulate the commons*. Mutual coercion, mutually agreed upon. Regulation must be enforced by policing and penalties
			* It makes an indirect feedback link from the condition of the resource to regulators to users. 
			* This can only work if the regulators aren't weak or corrupt, and the mutual coercion agreement is consistently implemented and it is clear why it exists. 
			* The mutual coercion agreement limits the freedom to abuse the commons while preserving the freedom to use it. 

* **Drift to Low Performance** - [[Egocentric Biases|Allowing]] performance standards to be influenced by past performance, especially if there is a negative bias in perceiving past performance, sets up a reinforcing feedback loop of *eroding goals that sets a system drifting towards low performance*. 
	* The actors tend to [[Logical Fallacy Biases|believe]] bad news [[Framing Effect|more]] than good news. The perceived state in turn affects performance. 
	* This is especially bad when the performance decline is gradual. 
	* Remedies: 
		* Keep standards absolute regardless of performance. 
		* Make goals sensitive to the best performances of the past, instead of the worst. 

* **Escalation** - When the state of one stock is determined by trying to surpass the state of another stock and vice versa. *There is a reinforcing feedback loop carrying the system into an arms race.* 
	* The escalation is exponential and can lead to extremes surprisingly quickly. If nothing is done, the spiral will be stopped by someone's collapse because exponential growth cannot go on forever.
	* The reinforcing feedback loop of an escalating system is not easy to stop. 
	* Remedies 
		* *Unilateral disarmament* - deliberately reduce your own system state to induce reductions in your competitor's state. 
		* *Negotiate a disarmament* - create balancing controlling loops to keep the competition in bounds. 
	* Disarmament ends up being better than staying on the race. 

* **Success to the Successful** - *If the winners of a competition are systematically rewarded with the means to win again*, a reinforcing feedback loop is created by which, if allowed to proceed uninhibited, the winners eventually take all while the losers are eliminated [^succ_1]
	* Remedies
		* *Diversification* - incentivize the losers to get out of the game and start another one. 
			* It is not guaranteed if the winner can still crush all the losers. 
			* It is not a strategy for the poor. 
		* *Antitrust laws* - limit the fraction of the pie that a winner may win. 
			* Can be rendered useless by simply having a reward for the winners be leniency towards the antitrust laws. 
		* Have policies that level the playing field and removes the advantages of the strongest players 
		* Devise rewards for success that do not bias the next round of competition.

[^succ_1]: See [[Characterizing Real Networks and Network Phenomena|the Matthew Effect]].

* **Shifting the Burden to the Intervenor** - manifests in dependence and addiction. Arises when a solution to a systemic problem reduces or *disguises the system but does nothing to solve the problem.* It is a [[Persuasion|persuasive]] solution to the problem. 
	* Intervention can be a good thing when it keeps the system in a desired state. 
	* If the intervention designed to correct the problem causes the self-maintaining capacity of the original system to atrophy or erode, then a destructive reinforcing feedback loop is set in motion *More and more of the solution is then required*. 
	* The system will become more and more dependent on the intervention and less and less able to maintain its own desired state.
	* This trap happens for several reasons 
		* Lack of foresight from the intervenor. 
		* The individual may not think through the long-term negative effects of the intervention. 
	* Remedies:
		* Prevent the dependency from happening in the first place. 
		* Intervene in such a way that the system strengthens its ability to shoulder its own burden. *Help the system help itself*. Ask the following questions:
			* Why are the natural correction mechanisms failing?
			* How can obstacles to their success be removed?
			* How can mechanisms for their success be made more effective. 

* **Rule Beating** - Perverse behavior that *gives the appearance of obeying the rules or achieving the goals but distorts the system*. It becomes a problem when it leads the system to unnatural behaviors that make no sense at all in the absence of the rules. 
	* This often indicates that the design of the law should keep in mind the whole system, including its self-organizing, evasive possibilities. 
	* It is a response of the lower levels in a hierarchy to over-rigid or ill-defined rules from above.
	* Responses 
		* Stronger rules or enforcement to stamp out the self-organizing responses. Often this simply leads to greater rule beating. 
		* Make the rules clearer or better. 

* **Seeking the Wrong Goal** - when the goals are defined inaccurately or incompletely, *the system may obediently work to produce an unintended or unwanted result*.
	* Remember [[System Science|systems are designed with specific functions and behaviors]]. 
	* This may escalate to the point that changes in the environment or the rules would render the system useless. 
	* The remedy is to design the appropriate goals. 
		* A common problem that leads to seeking the wrong goal is mistaking effort for results. 


# Links 
* [[Thinking in Systems by Meadows|Meadows]] - Ch. 5 -
* [[Dynamic Games of Complete Information]] - more examples.
* [[System Opportunities]] - ways to fix these pathologies
