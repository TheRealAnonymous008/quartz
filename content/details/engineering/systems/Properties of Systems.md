* **Resilience** - the ability of the system to survive and persist within a variable environment. 
	* It arises from a rich structure of many feedback loops that can work in different ways to restore a system even after a large perturbation 
	* The system should have many, different, and potentially redundant balancing loops. 
	* **Meta-resilience** comes from the ability to restore or rebuild feedback loops. 
	* **Meta-meta-resilience** comes from the ability of feedback loops to [[Artificial Intelligence|learn, create and evolve]] complex, restorative, self-organizing structures. 
	* *Resilience does not imply constancy, in fact, rigidity proves to be the opposite of resilience.* 
	* Resilience is not so obvious without a whole-systems view. It is often sacrificed for something short-term. 
	* Resilience expands the possibilities afforded by the system, allowing it to explore more states without destabilizing. 

* **Self-organization** - the capacity of a system to make its own structure more complex. 
	* It produces heterogeneity and unpredictability. It can make new structures, but it requires the [[The Exploitation-Exploration Trade-Off|ability to experiment]]. 
	* These systems diversify and complexify, often from just [[Complex Systems|simple rules]].

* **Hierarchy** - as a consequence of self-organization, a hierarchy emerges. 
	* A complex system can  evolve from a simple system only if there are stable intermediate forms. 
	* They also serve to reduce the amount of information that any part of the system has to keep track of. 
	* They can be taken apart, and the subsystems formed can still function in their own right. 
	* When a system breaks down, it splits along its subsystem hierarchies. Thus, a reductionist point of view has merits in system science (although remember that subsystems also interact with each other)
	* *When a subsystem’s goals dominate at the expense of the total system’s goals, the resulting behavior is called* **suboptimization** [^1]. Of course, there is a [[Trade Offs|balance that must be struck]] between centralized and decentralized approaches
	* Hierarchical systems evolve from the bottom up. The purpose of the upper layers is to serve the purposes of the lower layers. 

[^1]: In other words, it is [[Game Theory - Strategy#Solving Games|not Pareto optimal]]

# Systems as Models 
* Systems are [[The Psychopathology of Everyday Things|conceptual models]] for the world around us. They usually have a strong congruence with the world. However, they often fall short of [[False Priors and Extension Neglect|representing]] the world fully
	* Systems fool us by presenting themselves as a series of events.
	* We are less likely to be surprised if we see how events accumulate into dynamic patterns of behavior.
	* *Behavior based models are more useful than event based ones* because they facilitate understanding of the underlying systems and have more predictive power. However, there are a few pitfalls 
		* They overemphasize flows and underemphasize stocks. 
		* In trying to find statistical links that relate flows to each other, we are trying to find something that does not exist. 
		* The predictive power of such models are better for short-term rather than long-term performance. 

* *Systems feature non-linear relationships* These nonlinearities make systems more difficult to understand. 
	* These non-linearities can also change the relative strengths of the feedback loops. 
	* *Non-linearities can cause dominance shifts among the feedback loops of the system.*.

* *Systems rarely have boundaries*. They rarely exist within a closed system.
	* Systems as models simplify this by delineating a system in study with other systems that very likely do not influence the system in a significant way based on what is being studied.
	* In the end, there is no single legitimate boundary that can be drawn around a system. 
	* Too narrow of a boundary can lead to surprises as external variables that do influence the system are not included in the model.
	* Too large of a boundary results in complicated analyses. 
	* [[Framing Effect]] applies in this case as we may be prone to setting the boundaries based on existing boundaries.

* *In systems, many causes can produce many effects* Any physical entity with multiple inputs and outputs is surrounded by layers of limits. 
	* At any given time, the input that is most important to a system is one that is most limiting. 
	* Changes in limiting factors tend to be the most impactful. 
	* As the system evolves, the input that is limiting also changes. One factor may become limiting or non-limiting in the future. 
	* *There will always be limits to growth.* They can be self-imposed. If they aren't they will be system imposed. 

* *Systems always feature delay*. It is surprising how long things change in a system. Stocks are delays, and most flows have delays. 
	* It is important to consider the scale of the delays that are important. Consider delays at the right level of granularity. 
	* When there are long delays in feedback loops, *some sort of foresight is essential*. To act only when a problem becomes obvious is to miss an important opportunity to solve the system. 

* *Human-based systems typically feature bounded rationality*. People act in their best interests based on the information they have even if it is to society's detriment. 
	* Perfect information is rarely present in a system. 
	* We have our own share of faulty [[Human Biases|biases]] which render it difficult to act rationally. 
	* One remedy to bounded rationality is to introduce more information. 
	* The right [[Knowing What To Do -- Constraints, Discoverability and Feedback|feedback]] also helps actors behave rationally as they impose corrective behavior. Incentives and constraints also help. 

# Links 
* [[System Dynamics]]
* [[Thinking in Systems by Meadows]] - Ch. 3 - 4