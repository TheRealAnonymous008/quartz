* Let $V$ be a [[Vector Space]] and $S$ a nonempty subset of $V$. A vector $x\in V$ is a **linear combination** of elements in $S$ if there exists a finite number of elements $y_1,\dots,y_n\in S$ and scalars $a_1,\dots a_n\in F$ such that
  
  $$
  x = a_1y_1+\dots +a_ny_n
  $$
# Linear Independence
* A subset $S$ of a vector space $V$ is said to be **linearly dependent** if there exists a finite number of distinct vectors $x_1,\dots, x_n\in S$ and scalars $a_1,\dots,a_n \ne 0$ such that
  $$
  a_1x_1+a_2x_2+\dots +a_n x_n = 0
  $$
  Otherwise, $S$ and its elements are said to be **linearly independent**

* *Any subset containing the zero vector must be linearly dependent* 
* The following are true about linear independence for any vector space
	* $\emptyset$ is linearly independent. 
	* A set consisting of a single non-zero vector is linearly independent.
	* For a linearly independent set, the only way to get the zero vector is by setting $a_1 = \dots = a_n = 0$

* (*Friedberg 1.6*) Let $S_1\subseteq S_2 \subseteq V$. If $S_1$ is linearly dependent, then so is $S_2$
  
  An immediate corollary: Let $S_1\subseteq S_2 \subseteq V$. If $S_2$ is linearly independent, then so is $S_1$

* A **maximal linearly independent subset** of $S$ is a subset $B$ of $S$ such that
	* $B$ is linearly independent
	* Any subset of $S$ that properly contains $B$ is linearly dependent.
# Span and Basis
* (*Friedberg 1.5*) If $S$ is a nonempty subset of a vector space $V$, then the set $W$ consisting of all linear combinations of elements of $S$ is a [[Vector Subspace|subspace]] of $V$. Moreover, $W$ is the smallest subspace of $V$ containing $S$.
  
  We call $W$ the **span** of $S$, denoted $\text{span}(S)$.
  
  We define $\text{span}(\emptyset) = \{0\}$

* A subset $S$ of a vector space $V$ **generates** $V$ if $\text{span}(S) = V$. 

* A **basis** $\beta$ for a vector space $V$ is a linearly independent subset of $V$ that generates $V$. We say that the elements of $\beta$ form a **basis** for $V$. A basis can be **ordered** if the order of the elements in the basis is important.
  
  We can generalize this definition to say that a basis is a *maximal linearly independent subset of $V$* (see *Friedberg 1.12*)

* (*Friedberg 1.7*) Let $V$ be a vector space and $\beta=\{\beta_1,\dots, \beta_n\} \subseteq V$. Then $\beta$ is a basis for $V$ if and only if each vector $y\in V$ can be *uniquely expressed as a linear combination* of the form
  $$
  y=a_1\beta_1 +\dots + a_2 \beta_2 
  $$
* (*Friedberg 1.8*) Let $S$ be a linearly independent subset of a vector space $V$ that is not in $S$. Then $S\cup \{x\}$ if and only if $x\in \text{span}(S)$
* (*Friedberg 1.9*) If $V$ is generated by a finite set $S_0$, then a subset of $S_0$ is a basis for $V$. Hence, $V$ has a finite basis.

* (*Friedberg 1.10*) **Basis Replacement Theorem** Let $V$ be a vector space having a basis $\beta$ containing exactly $n$ elements. Let $S=\{y_1,\dots,y_m\}$ be a linearly independent subset of $V$ containing $m\le n$ elements. 
  
  There exists $S \subseteq \beta$ containing exactly $n-m$ elements such that $\text{span}(S\cup S_1) = V$  
  
  In other words, *each element in the basis is replaceable*. 
	* (*Friedberg 1.10.1*) Any linearly independent subset of $V$ containing exactly $n$ elements is a basis for $V$. 
	* (*Friedberg 1.10.2*) Any subset containing more than $n$ elements is linearly dependent. Any linearly independent subset of $V$ contains at most $n$ elements 
	* (*Friedberg 1.10.3*) Every basis for $V$ contains exactly $n$ elements.
	* (*Friedberg 1.10.4*) Let $S$ be a subset of $V$ such that $\text{span}(S) = V$ and $S$ has at most $\dim V$ elements, then $S$ is a basis for $V$.
	* (*Friedberg 1.10.5*) **Extension Property** Let $S$ be a linearly independent subset of $V$. Then, there exists $S_1\subseteq \beta$ such that $S\cup S_1$ is a basis for $V$. *Every linearly independent subset of $V$ can be extended to a basis for $V$*

* The **dimension** of a vector space is the unique number of elements in each basis of $V$, denoted $\dim(V)$. A vector space is **finite-dimensional** if the dimension is finite and **infinite-dimensional** otherwise.

* (*Friedberg e1.6.19*) Let $\text{span}(S) = V$, and $\dim (V) = n$. Then a subset of $S$ is a basis for $V$. Moreover, $S$ contains at least at least $n$ elements. 

* (*Friedberg 1.12*) Let $V$ be a vector space and $S$ a subset that generates $V$. If $\beta$ is a maximal linearly independent subset of $S$, then $\beta$ is a basis for $V$.

* (*Friedberg 1.13*) Let $S$ be a linearly independent subset of a vector space $V$. There exists a maximal linearly independent subset of $V$ that contains $S$.
  
  Therefore, alongside (*Friedberg 1.12*) *Every vector space has a basis*. 

* One particularly important ordered basis is defined as follows.
  Let $\beta = \{x_1, \dots , x_n\}$ be an ordered basis for a finite dimensional vector space $V$. For $x\in V$ we define the **coordinate vector** of $x$ relative to $\beta$ denoted $[x]_\beta$ by 
  $$
  [x]_\beta = 
  \begin{pmatrix}
  a_1 \\
  \vdots \\
  a_n
  \end{pmatrix}
  $$
  where $x = \sum_{i=1}^n a_ix_i$. 
	* (*Friedberg e2.2.7*) Let $V$ be an $n$-dimensional vector space with an ordered basis $\beta$. Define $T:V\to F^n$ by $T(x)=[x]_\beta$. $T$ is linear.
   


# Links
* [[Linear Algebra by Friedberg Insel and Spence]]