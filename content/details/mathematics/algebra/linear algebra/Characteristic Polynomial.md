* If $A\in M_{n\times n}(F)$, the [[Determinant|polynomial]] $\det(A-tI_n)$ in the [[Polynomial Ring|indeterminate]] $t$ is called the **characteristic polynomial of $A$**
  
  Similarly for linear operators, if we have basis $\beta$ then $f(t)$ is called the **characteristic polynomial** defined as
  $$
  f(t) = \det(A-tI)
  $$

* (*Friedberg 5.8*) The characteristic polynomial of $A\in M_{n\times n}(F)$ is a polynomial of degree $n$ with leading coefficient $(-1)^n$
	* (*Friedberg 5.8.1*) Let $A\in M_{n\times n}(F)$ and $f(t)$ be the characteristic polynomial of $A$. Then
		* A scalar $\lambda$ is an [[Matrix Diagonalization|eigenvalue]] of $A$ if and only if $f(\lambda) = 0$
		* $A$ has at most $n$ distinct eigenvalues.
	* (*Friedberg 5.8.2*) The same results in (*Friedberg 5.8.1*) hold for linear operators as well.

* (*Friedberg 5.9*) Let $T$ be a linear operator on a vector space $V$ and $\lambda$ be an eigenvalue of $T$. A vector $x\in V$ is an eigenvector of $T$ corresponding to $\lambda$ if and only if $x\ne 0$ and $x\in N(T-\lambda I)$. 

* (*Friedberg e5.1.12a*) Similar matrices have the same characteristic polynomial.
* (*Friedberg e5.1.14*) $A$ and $A^T$ have the same characteristic polynomial, and hence the same eigenvalues.

* (*Friedberg e5.1.22*) Let $T$ be a linear operator on $V$ over $F$. If $g(t)\in F[x]$ (see notation in [[Polynomial Ring]]) and $x$ is an eigenvector of $T$ corresponding to $\lambda$, then 
  $$
  g(T)(x) = g(\lambda)x
  $$
* (*Friedberg 5.11*) The characteristic polynomial of any diagonalizable linear operator can be factored into linear factors. We say that the characteristic polynomial in this case **splits**.
 * The **algebraic multiplicity** of an eigenvalue $\lambda$ is the largest $k\in \mathbb{Z}^+$ such that $(t-\lambda)^k$ is a factor of the characteristic polynomial $f(t)$. We denote this as $\mu_T(\lambda)$ for linear transformation $T$.

* (*Friedberg 5.28*) **Cayley-Hamilton Theorem**. Let $T$ be a linear operator on a finite dimensional vector space $V$ and let $f(t)$ be the characteristic polynomial of $T$. Then
  $$
  f(T) = T_0
  $$
  That is, $T$ *satisfies its own characteristic polynomial*.
	* *Proof*: This is equivalent to showing that $f(T)(x)=0$ $\forall x\in V$. The result clearly holds if $x=0$. If $x\ne 0$ then consider the $T$-[[Invariant Subspace|cyclic subspace]] of $V$ generated by $x$, denoted $W$. On one hand, we have that 
	  $$
	  T^k(x) = -(a_0 + a_1T(x) + \dots + a_{k-1}T^{k-1}(x))
	  $$
	  
	  This in turn implies the characteristic polynomial of $T_W$ is expressible as 
	  $$
	  g(t) = (-1)^k (a_0 +a_1t +\dots + a_{k-1} t^{k-1} + t^k)
	  $$
	  And substituting $T$ we get
	  $$
	  g(T)(x) = (-1)^k (a_0 I + a_1 T + \dots + a_{k-1}T^k)(x) = 0
	  $$
	  Also, $g(t)$ divides $f(t)$. Therefore $f(T)(x)=0$. 
	* The result is also true for matrices. In such a case if $A\in M_{n\times n}(F)$ and $f(t)$ is its characteristic polynomial, then 
	  $$
	  f(A) = O
	  $$
	* A generalization of this concept is the [[Minimal Polynomial]]

# Links
* [[Linear Algebra by Friedberg Insel and Spence|Friedberg, Insel and Spence]]