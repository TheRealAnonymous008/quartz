# Nash Equilibrium
* The principles applied [[Static Games of Complete Information|here]] are applicable in the analysis of dynamic games of complete information since *we can convert extensive-form to normal-form* (see [[Game Theory - Games|here]]).  In doing so, we can capture all the Nash Equilibria of the dynamic game. 
	* In an extensive game, every outcome of the game is associated with a *unique path of play* determined by some Nash Equilibrium in the game. 
	  
	  More formally, let $\sigma^\ast=(\sigma_1^\ast,\dots,\sigma_n^\ast)$ be a Nash equilibrium profile of behavioral strategies in an extensive form game. An information set is **on the equilibrium path** if given $\sigma^\ast$ it is reached with positive probability [^1]. 
	  
	  An information set is **off the equilibrium path** if it is never reached.

* In a Nash Equilibrium, players choose to proceed on the equilibrium path because of their beliefs about what the players are doing on and off the equilibrium path. 
	* However, because normal-form games treat all choices as "once-and-for-all" simultaneous choices, *beliefs can never be challenged and the player may not respond optimally*
	* Players only act rationally on the equilibrium path based on the belief on what happens both on and off the equilibrium path. However, *there is no restriction on the beliefs of players off the equilibrium path*. 
	* This is in contrast to what we might expect where players can respond optimally wherever they are called to move.

[^1]: Analogous to support

# Sequential Rationality 
* Given strategies $\sigma_{-i}\in \Delta S_{-i}$, we say that $\sigma_i$ is **sequentially rational** if and only if $i$ is playing a best response to $\sigma_{-i}$ in each of his information sets. 
* A **backward induction** procedure is one where we start from the terminal nodes at the end of the game and work our way up the decision tree to its root.
	* (*Tadelis 8.1*) **Zermelo's Theorem**- Any finite game of perfect information has a backward induction solution that is sequentially rational. Furthermore if no two terminal nodes prescribe the same payoffs to any player then the backward induction solution is unique.
	* *(Tadelis cor. 8.1)* Any finite game of perfect information has at least one sequentially rational Nash equilibrium in pure strategies. Furthermore if no two terminal nodes prescribe the same payoffs to any player then the game has a unique sequentially rational Nash equilibrium.

* *Backward induction cannot be applied to games of imperfect information, nor to games that do not end in finite time*. 

## Subgame-Perfect Nash Equilibrium 
* A **proper subgame** $G$ of an extensive-form game $\Gamma$ consists of only a single node and all its successors in $\Gamma$ with the property that if $x\in G$ and $x'\in h(x)$, then $x'\in G$. The subgame $G$ is a game [[Trees|tree]] that is a subtree of $\Gamma$.  
	* In other words, it is a smaller game within the larger game. 
	* A  playerâ€™s best response depends only on his beliefs about what the other players are doing within the subgame

* Let $\Gamma$ be an $n$-player extensive form game. A behavioral strategy profile $\sigma^\ast = (\sigma_1^\ast,\dots,\sigma_n^\ast)$ is a **subgame-perfect Nash equilibrium** if for every proper subgame $G$ of $\Gamma$, the restriction of $\sigma^\ast$ to $G$ is a Nash equilibrium in $G$.
	* $\sigma^\ast$ is a Nash equilibrium in all subgames, even those that are not reached in the equilibrium path.

* For any finite game of perfect information, the set of subgame-perfect Nash equilibria coincides with the set of Nash equilibria that survive backward induction. 
* *At least one of the Nash equilibria in a game will be a subgame-perfect equilibrium.*
* In other words, to check if $(\sigma_i^\ast, \sigma_{-i}^\ast)$ is a subgame-perfect equilibrium, we need to show that for every player $i$, given $\sigma_{-i}^\ast$, player $i$ does not have a single information set from which he would want to deviate .

# Multistage Games 
* A multistage game can be viewed as an extensive-form game. 
* Players should  anticipate future games and use them to create a richer environment for themselves
* Players will benefit from using future play to create incentives that constrain their behavior in earlier stages.

 * (*Tadelis 9.1*) Consider a multigame with $T$ stages, and let $\sigma^{t\ast}$ be a Nash equilibrium strategy profile for the $t$-th stage game. There exists a subgame-perfect equilibrium in the multistage game in which the equilibrium path coincides with the path generated by $\sigma^{1\ast},\dots, \sigma^{T\ast}$.  [^9.1]
	 * If we look at a sequence of plays that is a Nash equilibrium in each game independently then players should be content playing these stage-game strategies in each stage-game. *Each stage game can be treated as if they were independent games*.

[^9.1]: This follows from the fact that current play does not affect future play.

* (*Tadelis 9.2*) If $\sigma^\ast$ is a Nash equilibrium of the multistage game consisting of $G_1,\dots, G_T$ as stage games, then the restriction of $\sigma^\ast$ to the stage-game in period $T$ must be a Nash equilibrium of that stage .
	* *In the last stage game, the players must play a Nash Equilibrium of that stage game*. This follows from the fact that there is no future that can depend on the last action, ergo, the players should play a Nash Equilibrium 

* (*Tadelis 9.3*) If a finite multistage game consists of stage-games that each have a unique Nash equilibrium then the multistage game has a unique subgame-perfect equilibrium.
	* Because of (*Tadelis 9.2*), we must have that the penultimate game must also be independent of the future (since the next game is independent of the future) and so the unique Nash Equilibrium of that stage must be played. 

* A Nash Equilibrium need not be played in the early stage games when: 
	* There must be at least two distinct equilibria in some middle stage, a carrot (reward) and a stick (punishment)
	* *The discount factor has to be large enough* for the difference in payoff  between the carrot and the stick to have enough impact in the first stage of the game. *Long term losses must outweigh short term gains*. 

## One Stage Deviation Principle 
* A strategy is **optimal** if there is no strategy $\sigma'_i$ such that 
  $$
  v_i(\sigma_i',h_i) > v_i (\sigma_i, h_i)
  $$
  
* A strategy is **one-stage improvable** if there is no information set $h_i$, action $a\in A_i(h_i)$ and corresponding strategy $\sigma_i^{a,h_i}$ such that 
  $$
  v_i(\sigma_i^{a,h_i},h_i) >  v_i(\sigma_i, h_i)
  $$

* (*Tadelis Thm. 9.1*) **One Stage Deviation Principle** A one stage unimprovable strategy is optimal
	* *Intuition*: If $\sigma_i$ were not optimal, then we can find deviations that improve it. Because the game is finite, having finite strategies, the sequence of deviations performed must terminate.

* In other words: *if no player can increase their expected payoff by deviating from their original strategy via a single action (in just one stage of the game), then the strategy profile is a subgame-perfect equilibrium*.

# Repeated Games 
## Finitely Repeating Games 
* (*Tadelis 10.1*) If the stage-game of a finitely repeated game has a unique Nash equilibrium, then the finitely repeated game has a unique subgame-perfect equilibrium. [^10.1]

* *Because it is common knowledge that the game will end, players will not have the rewards and punishment incentives*. At the very last game, they can choose to maximize their profits and this effect cascades all the way to the beginning of the game. 

[^10.1]: A special case of *Tadelis 9.3*

## Infinitely Repeating Games 
* A profile of pure / behavioral strategies $(s^\ast_1(\cdot), \dots, s^\ast_n(\cdot))$, $s_i : H\to S_i$ is a **subgame-perfect equilibrium** if the restriction of  $(s^\ast_1(\cdot), \dots, s^\ast_n(\cdot))$ is a Nash equilibrium in every subgame.
  
  That is, for any history of the game $h_t$ is the continuation play dictated by the strategy profile is a Nash Equilibrium. 


* (*Tadelis 10.2*). Let $G(\gamma)$ be an infinitely repeated game, and $\sigma^\ast = (\sigma_1^\ast, \dots, \sigma_n^\ast)$ be a static Nash equilibrium strategy profile of the stage-game $G$. 
  
  Define the repeated-game strategy for each player $i$ to be the history-independent Nash strategy $\sigma_i^\ast(h_i)=\sigma_i^\ast$ for all $h\in H$. 
  
  Then  $\sigma^\ast$ is a subgame perfect equilibrium in the repeated game for any $\gamma < 1$  [^10.2]

[^10.2]: Follows similar logic to *Tadelis 9.1*. Future behavior of opponents is independent of history so history has no role for current play.

* *We can use a subgame-perfect equilibrium to support itself*. That is, the very knowledge of the subgame-perfect equilibrium is enough to support itself. We call such equilibria **bootstrap equilibria**
* **Grim trigger strategies** - a strategy wherein the player cooperates for as long as other players have cooperated. After which, if any player has deviated in the past, the player deviates permanently.
	* The grim trigger is itself an incentive for players to cooperate long-term and to ignore short-term temptations.
	* In effect, the payoff captures not only the reward today, but the reward for maintaining the status quo.
	* *If the players are patient (high enough $\gamma$) there is a reward-and-punishment strategy that keeps them cooperating forever*. If the future is certain to end, then the players will deviate at no repercussion.
  
* (*Tadelis 10.3*) In an infinitely repeated game $G(\gamma)$ a profile of strategies $\sigma^\ast$ is a subgame perfect equilibrium if and only if there is no player $i$ and no single history $h_{i-1}$ for which player $i$ would gain from deviating from $s_i(h_{i-1})$. [^10.3]

[^10.3]: Logic follows from *Tadelis Thm 9.1*. We have two [[Finite Automata and Regular Languages|states]]- the norm and the deviation.  The deviation state is a trap state. 

* (*Tadelis Thm 10.1*) **The Folk Theorem**. Let $G$ be a finite, simultaneous-move game of complete information. Let $(v_1^\ast, \dots, v_n^\ast)$ denote the payoffs from a Nash Equilibrium of $G$ and $(v_1,\dots,v_n)$ be a feasible payoff of $G$ (that is, a payoff achieved by combinations of stage game strategies). 
  
  If $v_i > v_i^\ast$ $\forall i\in N$ and if $\gamma$ is significantly close to $1$, then there exists a subgame-perfect equilibrium of the infinitely repeated game $G(\gamma)$ that achieves an average payoff arbitrarily close to $(v_1,\dots,v_n)$. [^Folk]

[^Folk]: The intuition is that the payoff vector, which is in the [[Convex Geometry|convex]] hull, is a weighted average of some combination of payoffs that result from pure-strategy profiles. We can then construct a sequence of strategy profiles that will imitate the weights required to achieve $(v_1,\dots,v_n)$. A reward-and-punishment strategy is possible because $v_i > v^\ast_i$.  A high enough discount factor discourages players from deviating. 

## Reputation
* We can re-interpret the need for high discounting and an uncertain terminal period (necessary for infinitely repeating games) in a variety of ways. 

* *Cooperation as Reputation*. Players in a repeated relationship can create a reputation to cooperate with each other. Sudden uncooperative behavior is rewarded with a grim-trigger strategy.
* *A third-party can be used as a reputation mechanism*. The idea is that this third party will be able to sustain the reputation for supporting the good behavior of others since he is incentivized to do so. They can then be used to enforce good behavior because they are established as trustworthy.
* *Reputation can be transferred without third parties* - Reputation acquired under the name of a firm or entity may be separated from the identity of the player who is operating under the firm's name. [^reputation]

[^reputation]: Hence even just the [[The 48 Laws of Power#5. So Much Depends On Reputation -- Guard It with your Life|reputation of a good name]] can do wonders for a brand


# Example Games  
* The **Centipede Game**
![[Centipede Game.png]]
<figcaption> Centipede Game </figcaption>
* Based on empirical experiments with the game: When players are expected to share common knowledge of rationality they indeed play the backward induction solution.

* **Stackelberg Model of Duopoly** - a sequential version of the Cournot game wherein price is fixed and quantity is set. The only difference is firm 1 chooses first before firm 2. 

* **Tacit Collusions** - an infinitely repeated game played by two firms wherein they must tacitly agree to share the rewards from holding a shared monopoly. It illustrates two things: 
	* If the two firms can agree to a game-theoretic view, they can circumvent any explicit rules against collusion. 
	* Price wars between colluding firms are off-the-equilibrium path behavior that occurs when collusive behavior is no longer a subgame-perfect equilibrium (i.e., due to uncertainty in the other players' tacit agreement ). 

## [[Strategic Bargaining]]

# Links
* [[Game Theory -- An Introduction by Tadelis|Tadelis Ch. 7 - 11]].
	* 10.4 - an application of Infinitely repeated games - namely Tacit Collusion
* [[Game Theory - Strategy]]