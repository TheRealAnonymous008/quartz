* The goal of **representation learning** is to extract sufficient but minimal [[Information Theory|information]] from data
* Representation learning builds on top of feature engineering by: 
	* Being automated
	* Not requiring domain expertise.
	* Being unbiased
* *The evaluation of a learned representation is related to the performance of downstream tasks that use this representation*

# Topics
* [[Convolutional Neural Network]] - the convolutional kernels in a CNN are feature extractors. 
* [[Encoder-Decoder Network]] - Encoders in particular can produce latent space representations. 
* [[Transformer Model]] - The attention layers used by a transformer model provide a form of representation learning.
* [[Graph Neural Network]] - Learns representation for network based data. 
	* [[Graph Embedding]] - non deep learning related techniques for embedding graphs
* [[Transfer Learning]]
* [[Belief Network]]
# Links
* [[Graph Neural Networks -- Foundations, Frontiers and Applications by Wu et al.]]